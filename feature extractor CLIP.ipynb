{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as T\n",
    "def process_video(video_name, label_file_path, output_dir, model, preprocess, root_dir, challenge, device):\n",
    "    try:\n",
    "        output_file = os.path.join(output_dir, f\"{video_name}.txt\")\n",
    "        \n",
    "        # Skip processing if output file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"Skipping {video_name}: output file already exists.\")\n",
    "            return\n",
    "        \n",
    "        # Locate the video folder\n",
    "        video_folder = None\n",
    "        for batch in ['batch1', 'batch2']:\n",
    "            possible_path = os.path.join(root_dir, batch, 'cropped_aligned', video_name)\n",
    "            if os.path.exists(possible_path):\n",
    "                video_folder = possible_path\n",
    "                break\n",
    "\n",
    "        if video_folder is None:\n",
    "            print(f\"Skipping {video_name}: video folder not found.\")\n",
    "            return\n",
    "\n",
    "        # Read label file\n",
    "        with open(label_file_path, 'r') as file:\n",
    "            lines = file.readlines()[1:]  # Skip header row\n",
    "\n",
    "        # Get sorted frame paths\n",
    "        frame_paths = sorted([os.path.join(video_folder, frame) for frame in os.listdir(video_folder) if frame.endswith('.jpg')])\n",
    "\n",
    "        with open(output_file, \"w\") as f:\n",
    "            for frame_path, label in zip(frame_paths, lines):\n",
    "                frame_label = list(map(float, label.strip().split(',')))\n",
    "\n",
    "                # Load and preprocess the image\n",
    "                image = Image.open(frame_path).convert('RGB')\n",
    "                image = preprocess(image).unsqueeze(0).to(device)  # Prepare for model\n",
    "\n",
    "                # Extract features\n",
    "                with torch.no_grad():\n",
    "                    features = model.encode_image(image).squeeze().cpu().numpy()\n",
    "\n",
    "                # Write features and labels\n",
    "                line = ','.join(map(str, features)) + ',' + ','.join(map(str, frame_label)) + '\\n'\n",
    "                f.write(line)\n",
    "\n",
    "        print(f\"Processed {video_name} -> {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_name}: {str(e)}\")\n",
    "\n",
    "def extract_and_save_features(root_dir, label_dir, challenge, output_root):\n",
    "    # Load CLIP model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(\"ViT-B-16\", pretrained=\"openai\")\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    challenge_folders = {'AU': 'AU_Detection_Challenge', 'EXPR': 'EXPR_Recognition_Challenge', 'VA': 'VA_Estimation_Challenge'}\n",
    "    if challenge not in challenge_folders:\n",
    "        raise ValueError(f\"Invalid challenge: {challenge}. Must be 'AU', 'EXPR', or 'VA'.\")\n",
    "\n",
    "    challenge_folder = challenge_folders[challenge]\n",
    "    train_label_folder = os.path.join(label_dir, challenge_folder, 'Train_Set')\n",
    "    val_label_folder = os.path.join(label_dir, challenge_folder, 'Validation_Set')\n",
    "    train_output_dir = os.path.join(output_root, challenge, 'training_set_features')\n",
    "    val_output_dir = os.path.join(output_root, challenge, 'validation_set_features')\n",
    "    os.makedirs(train_output_dir, exist_ok=True)\n",
    "    os.makedirs(val_output_dir, exist_ok=True)\n",
    "\n",
    "    label_files = [(folder, output_dir, f) for folder, output_dir in [(train_label_folder, train_output_dir), (val_label_folder, val_output_dir)] if os.path.exists(folder) for f in os.listdir(folder) if f.endswith('.txt')]\n",
    "    \n",
    "    if not label_files:\n",
    "        raise FileNotFoundError(f\"No label files found in {train_label_folder} or {val_label_folder}.\")\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        with tqdm(total=len(label_files), desc=\"Processing videos\") as pbar:\n",
    "            for label_folder, output_dir, label_file in label_files:\n",
    "                video_name = label_file.replace('.txt', '')\n",
    "                label_file_path = os.path.join(label_folder, label_file)\n",
    "                futures.append(executor.submit(process_video, video_name, label_file_path, output_dir, model, preprocess, root_dir, challenge, device))\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "    print(f\"Feature extraction completed for {challenge}. Files saved in {output_root}/{challenge}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "root_dir = \"../8th_ABAW\"  # Replace with actual path (batch1, batch2)\n",
    "label_dir = \"6th_ABAW_Annotations\"  # Replace with actual path\n",
    "\n",
    "# Define transformations (resize, normalize, convert to tensor)\n",
    "transform = T.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenges = [\"VA\",\"EXPR\",\"AU\"]    \n",
    "for i in challenges:\n",
    "    extract_and_save_features(\n",
    "  \n",
    "        root_dir=root_dir,  # Root dataset directory\n",
    "        label_dir=label_dir,  # Label directory\n",
    "        challenge=i,  # 'AU', 'EXPR', or 'VA'\n",
    "        output_root=\"Features_CLIP\"  # Where to save extracted features\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
